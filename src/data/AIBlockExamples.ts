// @ts-nocheck
/**
 * AI Block Examples for µLM Workspace
 * Pre-defined blocks with complete implementations for demo and development
 */

import { BlockDefinition } from '../storage/types/GridTypes';

// =============================================================================
// INPUT & DATA PROCESSING BLOCKS
// =============================================================================

export const DataLoaderBlock: BlockDefinition = {
  id: 'data-loader',
  name: 'Data Loader',
  category: 'input',
  description: 'Load and preprocess various data formats (CSV, JSON, TXT)',
  version: '1.0.0',
  inputs: [
    { id: 'file_path', name: 'File Path', type: 'text', description: 'Path to the data file', required: true },
    { id: 'format', name: 'Format', type: 'text', description: 'Data format (csv, json, txt)', required: false }
  ],
  outputs: [
    { id: 'data', name: 'Loaded Data', type: 'dataframe', description: 'Processed data ready for analysis', required: true },
    { id: 'metadata', name: 'Metadata', type: 'object', description: 'File metadata and statistics', required: false }
  ],
  config: {
    encoding: { type: 'select', label: 'Encoding', options: ['utf-8', 'latin-1', 'ascii'], default: 'utf-8' },
    delimiter: { type: 'text', label: 'CSV Delimiter', default: ',' },
    header: { type: 'boolean', label: 'Has Header', default: true }
  },
  implementation: `"""
Data Loader Block - Load and preprocess various data formats
Auto-generated by µLM AI Block Generator
"""

import pandas as pd
import json
import os
from typing import Dict, Any, Optional

class DataLoader:
    """
    Load and preprocess various data formats (CSV, JSON, TXT)
    
    Category: input
    Complexity: simple
    """
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize the Data Loader block with configuration"""
        self.config = config
        self.encoding = config.get('encoding', 'utf-8')
        self.delimiter = config.get('delimiter', ',')
        self.header = config.get('header', True)
        
        # Initialize any required models or resources
        self._initialize_resources()
    
    def _initialize_resources(self):
        """Initialize any required resources, models, or connections"""
        self.supported_formats = ['.csv', '.json', '.txt', '.tsv']
        
    def _validate_inputs(self, inputs: Dict[str, Any]) -> bool:
        """Validate input data"""
        if 'file_path' not in inputs:
            return False
        return os.path.exists(inputs['file_path'])
    
    def _process_data(self, file_path: str, format_hint: Optional[str] = None) -> tuple:
        """Process the data based on file format"""
        # Auto-detect format if not provided
        if not format_hint:
            _, ext = os.path.splitext(file_path)
            format_hint = ext.lower()
        
        if format_hint in ['.csv', 'csv']:
            data = pd.read_csv(file_path, encoding=self.encoding, 
                             delimiter=self.delimiter, header=0 if self.header else None)
        elif format_hint in ['.json', 'json']:
            with open(file_path, 'r', encoding=self.encoding) as f:
                json_data = json.load(f)
            data = pd.json_normalize(json_data) if isinstance(json_data, list) else pd.DataFrame([json_data])
        elif format_hint in ['.txt', 'txt']:
            with open(file_path, 'r', encoding=self.encoding) as f:
                lines = f.readlines()
            data = pd.DataFrame({'text': [line.strip() for line in lines]})
        else:
            raise ValueError(f"Unsupported format: {format_hint}")
        
        # Generate metadata
        metadata = {
            'shape': data.shape,
            'columns': list(data.columns),
            'dtypes': data.dtypes.to_dict(),
            'memory_usage': data.memory_usage(deep=True).sum(),
            'null_counts': data.isnull().sum().to_dict()
        }
        
        return data, metadata
    
    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        Main execution method for the block
        
        Args:
            inputs: Dictionary containing input data from connected blocks
            
        Returns:
            Dictionary containing output data for connected blocks
        """
        try:
            # Validate inputs
            if not self._validate_inputs(inputs):
                return {"success": False, "error": "Invalid file path or file does not exist"}
            
            # Extract primary input data
            file_path = inputs.get('file_path')
            format_hint = inputs.get('format')
            
            # Process the data
            data, metadata = self._process_data(file_path, format_hint)
            
            # Prepare outputs
            outputs = {
                "success": True,
                "data": data,
                "metadata": metadata
            }
            
            return outputs
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Error in Data Loader: {str(e)}"
            }
    
    def get_info(self) -> Dict[str, Any]:
        """Get block metadata and information"""
        return {
            "id": "data-loader",
            "name": "Data Loader",
            "category": "input",
            "description": "Load and preprocess various data formats (CSV, JSON, TXT)",
            "version": "1.0.0",
            "supported_formats": self.supported_formats,
            "config": self.config
        }`,
  tags: ['data', 'input', 'preprocessing'],
  performance: { avgExecutionTime: 500, memoryUsage: 'medium' },
  errorHandling: { retryable: true, timeout: 10000 },
  metadata: { author: 'µLM AI', documentation: 'Load and preprocess data files', isGenerated: false }
};

// =============================================================================
// ML & AI PROCESSING BLOCKS  
// =============================================================================

export const SentimentAnalysisBlock: BlockDefinition = {
  id: 'sentiment-analysis',
  name: 'Sentiment Analysis',
  category: 'mlAlgorithm',
  description: 'Analyze sentiment of text using pre-trained transformer models',
  version: '1.0.0',
  inputs: [
    { id: 'text', name: 'Text Data', type: 'text', description: 'Text to analyze for sentiment', required: true }
  ],
  outputs: [
    { id: 'sentiment', name: 'Sentiment Score', type: 'object', description: 'Sentiment classification with confidence', required: true },
    { id: 'confidence', name: 'Confidence', type: 'number', description: 'Prediction confidence score', required: false }
  ],
  config: {
    model: { type: 'select', label: 'Model', options: ['cardiffnlp/twitter-roberta-base-sentiment-latest', 'distilbert-base-uncased'], default: 'cardiffnlp/twitter-roberta-base-sentiment-latest' },
    batch_size: { type: 'number', label: 'Batch Size', default: 16, min: 1, max: 64 }
  },
  implementation: `"""
Sentiment Analysis Block - Analyze sentiment using transformer models
Auto-generated by µLM AI Block Generator
"""

from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from typing import Dict, Any, List, Union
import torch
import numpy as np

class SentimentAnalysis:
    """
    Analyze sentiment of text using pre-trained transformer models
    
    Category: mlAlgorithm
    Complexity: intermediate
    """
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize the Sentiment Analysis block with configuration"""
        self.config = config
        self.model_name = config.get('model', 'cardiffnlp/twitter-roberta-base-sentiment-latest')
        self.batch_size = config.get('batch_size', 16)
        
        # Initialize model and tokenizer
        self._initialize_resources()
    
    def _initialize_resources(self):
        """Initialize sentiment analysis pipeline"""
        try:
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis",
                model=self.model_name,
                return_all_scores=True,
                device=0 if torch.cuda.is_available() else -1
            )
            print(f"✅ Loaded sentiment model: {self.model_name}")
        except Exception as e:
            print(f"⚠️ Failed to load model, using default: {e}")
            self.sentiment_pipeline = pipeline("sentiment-analysis", return_all_scores=True)
    
    def _validate_inputs(self, inputs: Dict[str, Any]) -> bool:
        """Validate input data"""
        if 'text' not in inputs:
            return False
        text_data = inputs['text']
        return isinstance(text_data, (str, list)) and text_data
    
    def _process_single_text(self, text: str) -> Dict[str, Any]:
        """Process a single text for sentiment"""
        if not isinstance(text, str) or not text.strip():
            return {"sentiment": "neutral", "confidence": 0.0, "scores": {}}
        
        # Get sentiment scores
        results = self.sentiment_pipeline(text[:512])  # Truncate to model limit
        
        # Process results
        scores = {result['label'].lower(): result['score'] for result in results[0]}
        
        # Determine primary sentiment
        best_sentiment = max(scores.keys(), key=lambda k: scores[k])
        confidence = scores[best_sentiment]
        
        return {
            "sentiment": best_sentiment,
            "confidence": confidence,
            "scores": scores
        }
    
    def _process_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """Process multiple texts efficiently"""
        # Clean and prepare texts
        clean_texts = [text[:512] if isinstance(text, str) else "" for text in texts]
        
        # Process in batches
        results = []
        for i in range(0, len(clean_texts), self.batch_size):
            batch = clean_texts[i:i+self.batch_size]
            batch_results = self.sentiment_pipeline(batch)
            
            for text_results in batch_results:
                scores = {result['label'].lower(): result['score'] for result in text_results}
                best_sentiment = max(scores.keys(), key=lambda k: scores[k])
                confidence = scores[best_sentiment]
                
                results.append({
                    "sentiment": best_sentiment,
                    "confidence": confidence,
                    "scores": scores
                })
        
        return results
    
    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        Main execution method for the block
        
        Args:
            inputs: Dictionary containing input data from connected blocks
            
        Returns:
            Dictionary containing output data for connected blocks
        """
        try:
            # Validate inputs
            if not self._validate_inputs(inputs):
                return {"success": False, "error": "Invalid or missing text input"}
            
            # Extract input data
            text_data = inputs.get('text')
            
            # Process based on input type
            if isinstance(text_data, str):
                result = self._process_single_text(text_data)
                outputs = {
                    "success": True,
                    "sentiment": result,
                    "confidence": result["confidence"]
                }
            elif isinstance(text_data, list):
                results = self._process_batch(text_data)
                # Calculate aggregate metrics
                avg_confidence = np.mean([r["confidence"] for r in results])
                sentiment_counts = {}
                for r in results:
                    sentiment_counts[r["sentiment"]] = sentiment_counts.get(r["sentiment"], 0) + 1
                
                outputs = {
                    "success": True,
                    "sentiment": {
                        "individual_results": results,
                        "aggregate": {
                            "avg_confidence": avg_confidence,
                            "sentiment_distribution": sentiment_counts,
                            "total_processed": len(results)
                        }
                    },
                    "confidence": avg_confidence
                }
            else:
                return {"success": False, "error": "Text input must be string or list of strings"}
            
            return outputs
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Error in Sentiment Analysis: {str(e)}"
            }
    
    def get_info(self) -> Dict[str, Any]:
        """Get block metadata and information"""
        return {
            "id": "sentiment-analysis",
            "name": "Sentiment Analysis",
            "category": "mlAlgorithm", 
            "description": "Analyze sentiment of text using pre-trained transformer models",
            "version": "1.0.0",
            "model": self.model_name,
            "config": self.config
        }`,
  tags: ['nlp', 'sentiment', 'transformers', 'ai'],
  performance: { avgExecutionTime: 1200, memoryUsage: 'high' },
  errorHandling: { retryable: true, timeout: 30000 },
  metadata: { author: 'µLM AI', documentation: 'Sentiment analysis using transformer models', isGenerated: false }
};

// =============================================================================
// UTILITY & OUTPUT BLOCKS
// =============================================================================

export const DataVisualizerBlock: BlockDefinition = {
  id: 'data-visualizer',
  name: 'Data Visualizer',
  category: 'output',
  description: 'Create interactive charts and visualizations from data',
  version: '1.0.0',
  inputs: [
    { id: 'data', name: 'Data', type: 'dataframe', description: 'Data to visualize', required: true },
    { id: 'chart_type', name: 'Chart Type', type: 'text', description: 'Type of chart to create', required: false }
  ],
  outputs: [
    { id: 'chart', name: 'Chart Object', type: 'object', description: 'Generated chart object', required: true },
    { id: 'chart_url', name: 'Chart URL', type: 'text', description: 'URL to view the chart', required: false }
  ],
  config: {
    chart_type: { type: 'select', label: 'Default Chart Type', options: ['line', 'bar', 'scatter', 'histogram', 'box'], default: 'line' },
    width: { type: 'number', label: 'Width (px)', default: 800, min: 200, max: 2000 },
    height: { type: 'number', label: 'Height (px)', default: 600, min: 200, max: 1500 },
    theme: { type: 'select', label: 'Theme', options: ['plotly', 'plotly_white', 'plotly_dark', 'ggplot2', 'seaborn'], default: 'plotly' }
  },
  implementation: `"""
Data Visualizer Block - Create interactive charts and visualizations
Auto-generated by µLM AI Block Generator
"""

import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
import pandas as pd
from typing import Dict, Any, Optional
import uuid
import base64
import io

class DataVisualizer:
    """
    Create interactive charts and visualizations from data
    
    Category: output
    Complexity: intermediate
    """
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize the Data Visualizer block with configuration"""
        self.config = config
        self.chart_type = config.get('chart_type', 'line')
        self.width = config.get('width', 800)
        self.height = config.get('height', 600)
        self.theme = config.get('theme', 'plotly')
        
        # Initialize visualization resources
        self._initialize_resources()
    
    def _initialize_resources(self):
        """Initialize visualization resources"""
        pio.templates.default = self.theme
        self.chart_id = str(uuid.uuid4())
    
    def _validate_inputs(self, inputs: Dict[str, Any]) -> bool:
        """Validate input data"""
        if 'data' not in inputs:
            return False
        data = inputs['data']
        return isinstance(data, pd.DataFrame) and not data.empty
    
    def _auto_detect_chart_type(self, data: pd.DataFrame) -> str:
        """Auto-detect appropriate chart type based on data characteristics"""
        numeric_cols = data.select_dtypes(include=['number']).columns
        categorical_cols = data.select_dtypes(include=['object', 'category']).columns
        
        if len(numeric_cols) >= 2 and len(categorical_cols) == 0:
            return 'scatter'
        elif len(numeric_cols) == 1 and len(categorical_cols) >= 1:
            return 'bar'
        elif len(numeric_cols) >= 1:
            return 'histogram' if len(categorical_cols) == 0 else 'box'
        else:
            return 'bar'
    
    def _create_chart(self, data: pd.DataFrame, chart_type: str) -> go.Figure:
        """Create chart based on type and data"""
        numeric_cols = data.select_dtypes(include=['number']).columns
        categorical_cols = data.select_dtypes(include=['object', 'category']).columns
        
        if chart_type == 'line':
            if len(numeric_cols) >= 2:
                fig = px.line(data, x=numeric_cols[0], y=numeric_cols[1],
                            title=f"Line Chart: {numeric_cols[1]} vs {numeric_cols[0]}")
            else:
                fig = px.line(data, y=numeric_cols[0] if len(numeric_cols) > 0 else data.columns[0],
                            title="Line Chart")
        
        elif chart_type == 'bar':
            if len(categorical_cols) > 0 and len(numeric_cols) > 0:
                fig = px.bar(data, x=categorical_cols[0], y=numeric_cols[0],
                           title=f"Bar Chart: {numeric_cols[0]} by {categorical_cols[0]}")
            else:
                # Create count chart for categorical data
                fig = px.bar(x=data.columns, y=data.iloc[0] if len(data) > 0 else [0],
                           title="Bar Chart")
        
        elif chart_type == 'scatter':
            if len(numeric_cols) >= 2:
                color_col = categorical_cols[0] if len(categorical_cols) > 0 else None
                fig = px.scatter(data, x=numeric_cols[0], y=numeric_cols[1], color=color_col,
                               title=f"Scatter Plot: {numeric_cols[1]} vs {numeric_cols[0]}")
            else:
                fig = px.scatter(data, x=data.index, y=numeric_cols[0] if len(numeric_cols) > 0 else data.columns[0],
                               title="Scatter Plot")
        
        elif chart_type == 'histogram':
            col = numeric_cols[0] if len(numeric_cols) > 0 else data.columns[0]
            fig = px.histogram(data, x=col, title=f"Histogram: {col}")
        
        elif chart_type == 'box':
            if len(numeric_cols) > 0:
                fig = px.box(data, y=numeric_cols[0],
                           x=categorical_cols[0] if len(categorical_cols) > 0 else None,
                           title=f"Box Plot: {numeric_cols[0]}")
            else:
                fig = px.box(data, title="Box Plot")
        
        else:
            # Default to simple line chart
            fig = px.line(data.head(100), title="Data Overview")
        
        # Update layout
        fig.update_layout(
            width=self.width,
            height=self.height,
            template=self.theme,
            showlegend=True
        )
        
        return fig
    
    def _export_chart(self, fig: go.Figure) -> Dict[str, Any]:
        """Export chart in multiple formats"""
        # Generate HTML
        html_content = fig.to_html(include_plotlyjs='cdn')
        
        # Generate image (PNG) as base64
        img_bytes = fig.to_image(format="png", width=self.width, height=self.height)
        img_base64 = base64.b64encode(img_bytes).decode()
        
        # Generate JSON representation
        chart_json = fig.to_json()
        
        return {
            "html": html_content,
            "image_base64": img_base64,
            "json": chart_json,
            "chart_id": self.chart_id
        }
    
    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        Main execution method for the block
        
        Args:
            inputs: Dictionary containing input data from connected blocks
            
        Returns:
            Dictionary containing output data for connected blocks
        """
        try:
            # Validate inputs
            if not self._validate_inputs(inputs):
                return {"success": False, "error": "Invalid or empty DataFrame input"}
            
            # Extract input data
            data = inputs.get('data')
            requested_chart_type = inputs.get('chart_type', self.chart_type)
            
            # Auto-detect chart type if needed
            if requested_chart_type == 'auto':
                requested_chart_type = self._auto_detect_chart_type(data)
            
            # Create the chart
            fig = self._create_chart(data, requested_chart_type)
            
            # Export chart in multiple formats
            chart_exports = self._export_chart(fig)
            
            # Prepare outputs
            outputs = {
                "success": True,
                "chart": {
                    "figure": fig,
                    "exports": chart_exports,
                    "metadata": {
                        "chart_type": requested_chart_type,
                        "data_shape": data.shape,
                        "chart_id": self.chart_id
                    }
                },
                "chart_url": f"data:text/html;base64,{base64.b64encode(chart_exports['html'].encode()).decode()}"
            }
            
            return outputs
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Error in Data Visualizer: {str(e)}"
            }
    
    def get_info(self) -> Dict[str, Any]:
        """Get block metadata and information"""
        return {
            "id": "data-visualizer",
            "name": "Data Visualizer",
            "category": "output",
            "description": "Create interactive charts and visualizations from data",
            "version": "1.0.0",
            "supported_charts": ['line', 'bar', 'scatter', 'histogram', 'box'],
            "config": self.config
        }`,
  tags: ['visualization', 'charts', 'plotly', 'output'],
  performance: { avgExecutionTime: 800, memoryUsage: 'medium' },
  errorHandling: { retryable: true, timeout: 15000 },
  metadata: { author: 'µLM AI', documentation: 'Create interactive visualizations', isGenerated: false }
};

// =============================================================================
// EXPORT ALL BLOCKS
// =============================================================================

export const AIBlockExamples = {
  DataLoaderBlock,
  SentimentAnalysisBlock,
  DataVisualizerBlock
};

export const getAllBlocks = (): BlockDefinition[] => {
  return Object.values(AIBlockExamples);
};

export default AIBlockExamples;
